"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[4181],{8194:(e,n,o)=>{o.r(n),o.d(n,{assets:()=>c,contentTitle:()=>s,default:()=>u,frontMatter:()=>r,metadata:()=>a,toc:()=>l});var t=o(4848),i=o(8453);const r={},s="import_files.py",a={id:"sunholo/llamaindex/import_files",title:"import_files.py",description:"Source: sunholo/llamaindex/importfiles.py",source:"@site/docs/sunholo/llamaindex/import_files.md",sourceDirName:"sunholo/llamaindex",slug:"/sunholo/llamaindex/import_files",permalink:"/docs/sunholo/llamaindex/import_files",draft:!1,unlisted:!1,editUrl:"https://github.com/sunholo-data/sunholo-py/tree/main/docs/docs/sunholo/llamaindex/import_files.md",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"callback.py",permalink:"/docs/sunholo/langfuse/callback"},next:{title:"logging.py",permalink:"/docs/sunholo/logging"}},c={},l=[{value:"Functions",id:"functions",level:2},{value:"do_llamaindex(message_data, metadata, vector_name)",id:"do_llamaindexmessage_data-metadata-vector_name",level:3},{value:"get_corpus(gcp_config)",id:"get_corpusgcp_config",level:3},{value:"init_vertex(gcp_config)",id:"init_vertexgcp_config",level:3}];function d(e){const n={a:"a",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",li:"li",p:"p",pre:"pre",ul:"ul",...(0,i.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.h1,{id:"import_filespy",children:"import_files.py"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.em,{children:"Source"}),": ",(0,t.jsx)(n.a,{href:"https://github.com/sunholo-data/sunholo-py/blob/main/sunholo/llamaindex/import_files.py",children:"sunholo/llamaindex/import_files.py"})]}),"\n",(0,t.jsx)(n.h2,{id:"functions",children:"Functions"}),"\n",(0,t.jsx)(n.h3,{id:"do_llamaindexmessage_data-metadata-vector_name",children:"do_llamaindex(message_data, metadata, vector_name)"}),"\n",(0,t.jsx)(n.p,{children:"Configures and manages the corpus for a VertexAI project using the specified vector name\nby importing message data from Google Cloud Storage or Google Drive URLs."}),"\n",(0,t.jsx)(n.p,{children:"This function loads configuration from a YAML file, initializes a Vertex AI environment,\nand either fetches an existing corpus or creates a new one if it doesn't exist.\nIt supports importing files directly from cloud storage links."}),"\n",(0,t.jsx)(n.p,{children:"Parameters:\nmessage_data (str): The URL to the data on Google Cloud Storage or Google Drive that needs to be imported to the corpus.\nmetadata (dict): Additional metadata not explicitly used in this function but might be needed for extended functionality.\nvector_name (str): The name of the vector (and corpus) which will be used to locate and configure the specific settings from the configuration files."}),"\n",(0,t.jsx)(n.p,{children:"Raises:\nValueError: If the necessary configurations for GCP or project ID are not found, or if the corpus could not be established.\nNotImplementedError: If the data is not from supported sources (Google Cloud Storage or Google Drive)."}),"\n",(0,t.jsx)(n.p,{children:"Example:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'message_data = "gs://bucket_name/path_to_file.txt"\nmetadata = {"user": "admin"}\nvector_name = "example_vector"\nresponse = do_llamaindex(message_data, metadata, vector_name)\nprint(response)\n# Imported file to corpus: {\'status\': \'success\'}\n'})}),"\n",(0,t.jsx)(n.h3,{id:"get_corpusgcp_config",children:"get_corpus(gcp_config)"}),"\n",(0,t.jsx)(n.p,{children:"Retrieves a LlamaIndex corpus from Vertex AI based on the provided Google Cloud configuration."}),"\n",(0,t.jsx)(n.p,{children:"This function constructs a corpus name using project details from the configuration and attempts\nto fetch the corresponding corpus. If the corpus cannot be retrieved, it raises an error."}),"\n",(0,t.jsx)(n.p,{children:"Parameters:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["gcp_config (dict): Configuration dictionary that must include:","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"project_id (str): Google Cloud project identifier."}),"\n",(0,t.jsx)(n.li,{children:"location (str): Google Cloud location."}),"\n",(0,t.jsx)(n.li,{children:"rag_id (str): Identifier for the RAG (Retrieval-Augmented Generation) corpus."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"Returns:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"The corpus object fetched from Vertex AI."}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"Raises:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"ValueError: If any of the required configurations (project_id, location, or rag_id) are missing,\nor if the corpus cannot be retrieved."}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"Example:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"# Example configuration dictionary\ngcp_config = {\n    'project_id': 'your-project-id',\n    'location': 'your-location',\n    'rag_id': 'your-rag-id'\n}\n\n# Fetch the corpus\ntry:\n    corpus = get_corpus(gcp_config)\n    print(\"Corpus fetched successfully:\", corpus)\nexcept ValueError as e:\n    print(\"Error fetching corpus:\", str(e))\n"})}),"\n",(0,t.jsx)(n.h3,{id:"init_vertexgcp_config",children:"init_vertex(gcp_config)"}),"\n",(0,t.jsx)(n.p,{children:"Initializes the Vertex AI environment using the provided Google Cloud Platform configuration."}),"\n",(0,t.jsx)(n.p,{children:"This function configures the Vertex AI API session with specified project and location details\nfrom the gcp_config dictionary. It is essential to call this function at the beginning of a session\nbefore performing any operations related to Vertex AI."}),"\n",(0,t.jsx)(n.p,{children:"Parameters:\ngcp_config (dict): A dictionary containing the Google Cloud Platform configuration with keys:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"'project_id': The Google Cloud project ID to configure for Vertex AI."}),"\n",(0,t.jsx)(n.li,{children:"'location': The Google Cloud region to configure for Vertex AI."}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"Raises:\nKeyError: If the necessary keys ('project_id' or 'location') are missing in the gcp_config dictionary.\nModuleNotFoundError: If the Vertex AI module is not installed and needs to be installed via pip."}),"\n",(0,t.jsx)(n.p,{children:"Example:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"gcp_config = {\n     'project_id': 'your-project-id',\n     'location': 'us-central1'\n}\ninit_vertex(gcp_config)\n# This will initialize the Vertex AI session with the provided project ID and location.\n\nNote:\n    Ensure that the 'vertexai' module is installed and correctly configured before calling this function.\n    The function assumes that the required 'vertexai' library is available and that the logging setup is already in place.\n\n### llamaindex_chunker_check(message_data, metadata, vector_name)\n\nNo docstring available.\n\n"})})]})}function u(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},8453:(e,n,o)=>{o.d(n,{R:()=>s,x:()=>a});var t=o(6540);const i={},r=t.createContext(i);function s(e){const n=t.useContext(r);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:s(e.components),t.createElement(r.Provider,{value:n},e.children)}}}]);
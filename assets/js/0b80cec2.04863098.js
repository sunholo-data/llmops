"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[5930],{5983:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>r,contentTitle:()=>d,default:()=>h,frontMatter:()=>o,metadata:()=>a,toc:()=>c});var i=t(4848),s=t(8453);const o={},d="Embedding Pipelines",a={id:"howto/embedding",title:"Embedding Pipelines",description:"The configuration files include sections on what vector store will be used upon retrieval for context in a RAG pipeline.",source:"@site/docs/howto/embedding.md",sourceDirName:"howto",slug:"/howto/embedding",permalink:"/docs/howto/embedding",draft:!1,unlisted:!1,editUrl:"https://github.com/sunholo-data/sunholo-py/tree/main/docs/docs/howto/embedding.md",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"How To",permalink:"/docs/howto/"},next:{title:"Creating a Flask VAC app",permalink:"/docs/howto/flask_app"}},r={},c=[{value:"Embedding architecture",id:"embedding-architecture",level:2},{value:"Chunker size",id:"chunker-size",level:3},{value:"Chunker type: semantic",id:"chunker-type-semantic",level:3},{value:"Add documents for embedding",id:"add-documents-for-embedding",level:2},{value:"Adding to a bucket",id:"adding-to-a-bucket",level:3},{value:"Adding documents via the UIs",id:"adding-documents-via-the-uis",level:3},{value:"Using locally via <code>sunholo embed</code>",id:"using-locally-via-sunholo-embed",level:3},{value:"Metadata",id:"metadata",level:2}];function l(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",img:"img",li:"li",p:"p",pre:"pre",ul:"ul",...(0,s.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.h1,{id:"embedding-pipelines",children:"Embedding Pipelines"}),"\n",(0,i.jsx)(n.p,{children:"The configuration files include sections on what vector store will be used upon retrieval for context in a RAG pipeline."}),"\n",(0,i.jsx)(n.p,{children:"But to get the documents embedded in the first place is also controlled by the configuration - here is an example from Edmonbrain:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:"kind: vacConfig\napiVersion: v1\n  vac:\n    edmonbrain:\n      llm: openai\n      agent: edmonbrain\n      display_name: Edmonbrain\n      avatar_url: https://avatars.githubusercontent.com/u/3155884?s=48&v=4\n      description: This is the original [Edmonbrain](https://code.markedmondson.me/running-llms-on-gcp/) implementation that uses RAG to answer questions based on data you send in via its `!help` commands and learns from previous chat history.  It dreams each night that can also be used in its memory.\n      model: gpt-4o\n      memory_k: 10 # how many memories will be returned in total after relevancy compression\n      memory:\n        - personal-vectorstore:\n            vectorstore: lancedb\n            k: 10 #  how many candidate memory will be returned from this vectorstore\n        - eduvac-vectorstore:\n            vector_name: eduvac\n            read_only: true # can only read, not write embeddings\n            vectorstore: lancedb\n            k: 3 #  how many candidate memory will be returned from this vectorstore\n"})}),"\n",(0,i.jsxs)(n.p,{children:["In the above example two memory stores are defined: ",(0,i.jsx)(n.code,{children:"personal-vectorstore"})," and ",(0,i.jsx)(n.code,{children:"eduvac-vectorstore"}),".  Only those without ",(0,i.jsx)(n.code,{children:"read_only"})," will be used when adding documents, but being able to read from other VAC stores means you can set up knowledge sharing and authentication with differing levels of access, such as company wide, department and personal."]}),"\n",(0,i.jsx)(n.h2,{id:"embedding-architecture",children:"Embedding architecture"}),"\n",(0,i.jsx)(n.p,{children:"Three system VACs are used within most embedding pipelines:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"chunker"})," - parses out files and URLS sent to it and turns them into chunks ready for embedding."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"unstructured"})," - The ",(0,i.jsx)(n.code,{children:"chunker"})," can send files to this self-hosted unstructured.io servie for document parsing"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"emebedder"})," - receives chunks from ",(0,i.jsx)(n.code,{children:"chunker"})," and sends them to the appropriate vector store."]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"Taking advantage of the micro-service architecture means the pipeline can scale from 0 to many GBs per second of embedding."}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.code,{children:"vacConfig"})," can set the attributes of the embedding chunks per VAC, for instance picking the embedding model."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:"    embedder:\n      llm: openai # if different from llm is what embedding model uses\n"})}),"\n",(0,i.jsx)(n.p,{children:"Some LLM providers don't have embedding (e.g. Anthropic) so you can pick which embedding model can be used."}),"\n",(0,i.jsx)(n.h3,{id:"chunker-size",children:"Chunker size"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:"    chunker:\n      chunk_size: 1000\n      overlap: 200\n"})}),"\n",(0,i.jsx)(n.p,{children:"This lets you determine how big the chunks will be and what overlap they shall have with each other.  This can vary depending on your use case."}),"\n",(0,i.jsx)(n.h3,{id:"chunker-type-semantic",children:"Chunker type: semantic"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:"    chunker:\n      type: semantic\n      llm: openai\n      summarise:\n        llm: openai\n        model: gpt-3.5-turbo\n        threshold: 3000\n        model_limit: 30000\n"})}),"\n",(0,i.jsxs)(n.p,{children:["Instead of picking a chunk size you can use the experimental ",(0,i.jsx)(n.a,{href:"https://python.langchain.com/v0.2/docs/how_to/semantic-chunker/",children:"Langchain technique of semantic chunking"}),", which will vary the chunk size and cut them off according to similarity scores of each sentence's embedding score."]}),"\n",(0,i.jsx)(n.h2,{id:"add-documents-for-embedding",children:"Add documents for embedding"}),"\n",(0,i.jsx)(n.h3,{id:"adding-to-a-bucket",children:"Adding to a bucket"}),"\n",(0,i.jsxs)(n.p,{children:["If using Multivac, then embedding is activated when a file hits the designated cloud storage bucket.  A Pub/Sub notification sends the ",(0,i.jsx)(n.code,{children:"gs://"})," URI to the chunker VAC, which then parses and sends to the other embedding services such as ",(0,i.jsx)(n.code,{children:"unstructured"}),", ",(0,i.jsx)(n.code,{children:"embedder"})," and other document stores if configured."]}),"\n",(0,i.jsxs)(n.p,{children:["The Pub/Sub is also available to call directly, as well as the individual embedding services, for instance you may already have parsed text content and just want to send it to the ",(0,i.jsx)(n.code,{children:"embedder"})," service.  The overall pipeline is pretty quick, usually only taking under a minute to index big documents such as PDFs and PowerPoints, so it can be used in a live user session."]}),"\n",(0,i.jsx)(n.p,{children:"Often for batch pipelines a feeder bucket is used then an hourly Cloud Storage Transfer service will check the bucket for new files and transfer them across."}),"\n",(0,i.jsxs)(n.p,{children:["The folder of the embedding bucket determines the ",(0,i.jsx)(n.code,{children:"VAC"})," the documents are sent to, so for instance all files that land within ",(0,i.jsx)(n.code,{children:"edmonbrain/"})," are sent to the ",(0,i.jsx)(n.code,{children:"edmonbrain"})," vector stores."]}),"\n",(0,i.jsx)(n.h3,{id:"adding-documents-via-the-uis",children:"Adding documents via the UIs"}),"\n",(0,i.jsx)(n.p,{children:"Several of the Multivac clients such as the chat bots, web app or CLI support uploading files directly to the vector store.  Behind the scenes this is uploading the file to the embedding bucket for processing via the bucket pipeline above, or making a direct Pub/Sub call."}),"\n",(0,i.jsxs)(n.p,{children:["Several VACs support special commands to help with this, such as ",(0,i.jsx)(n.code,{children:"!saveurl"})," that will embed a URL after parsing, or ",(0,i.jsx)(n.code,{children:"!savethread"})," to store the current conversation thread as a text file.  For example via the ",(0,i.jsx)(n.code,{children:"sunholo CLI"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-sh",children:"sunholo vac chat edmonbrain\n\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Edmonbrain \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 This is the original [Edmonbrain](https://code.markedmondson.me/running-llms-on-gcp/)  \u2502\n\u2502 implementation that uses RAG to answer questions based on data you send in via its     \u2502\n\u2502 `!help` commands and learns from previous chat history.  It dreams each night that can \u2502\n\u2502 also be used in its memory.                                                            \u2502\n\u2570\u2500 stream: http://127.0.0.1:8081/vac/streaming/edmonbrain invoke: http://127.0.0.1:8081/\u2500\u256f\nYou: !saveurl https://docs.livekit.io/home/get-started/intro-to-livekit/\nedmonbrain: URLs sent for processing: \n['https://docs.livekit.io/home/get-started/intro-to-livekit/'] to edmonbrain.\n"})}),"\n",(0,i.jsx)(n.p,{children:"The URL contents are then available within ~1min for all clients using that VAC, such as the webapp:"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{src:t(7511).A+"",width:"1540",height:"1384"})}),"\n",(0,i.jsxs)(n.h3,{id:"using-locally-via-sunholo-embed",children:["Using locally via ",(0,i.jsx)(n.code,{children:"sunholo embed"})]}),"\n",(0,i.jsxs)(n.p,{children:["Since the services are available via API, ",(0,i.jsx)(n.code,{children:"curl"})," can also be used to send files to the embedding pipeline, however for convenience its easier to use the ",(0,i.jsx)(n.code,{children:"sunholo"})," cli installed via ",(0,i.jsx)(n.code,{children:"pip install sunholo[cli]"}),"."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-sh",children:"usage: sunholo embed [-h] [--embed-override EMBED_OVERRIDE] [--chunk-override CHUNK_OVERRIDE] [--no-proxy] [-m METADATA]\n                     [--local-chunks] [--is-file] [--only-chunk]\n                     vac_name data\n\npositional arguments:\n  vac_name              VAC service to embed the data for\n  data                  String content to send for embedding\n\noptional arguments:\n  -h, --help            show this help message and exit\n  --embed-override EMBED_OVERRIDE\n                        Override the embed VAC service URL.\n  --chunk-override CHUNK_OVERRIDE\n                        Override the chunk VAC service URL.\n  --no-proxy            Do not use the proxy and connect directly to the VAC service.\n  -m METADATA, --metadata METADATA\n                        Metadata to send with the embedding (as JSON string).\n  --local-chunks        Whether to process chunks to embed locally, or via the cloud.\n  --is-file             Indicate if the data argument is a file path\n  --only-chunk          Whether to only parse the document and return the chunks locally, with no embedding\n"})}),"\n",(0,i.jsxs)(n.p,{children:["See the ",(0,i.jsx)(n.a,{href:"../cli/#sunholo-embed",children:(0,i.jsx)(n.code,{children:"sunholo embed"})})," documentation for more information."]}),"\n",(0,i.jsx)(n.h2,{id:"metadata",children:"Metadata"}),"\n",(0,i.jsx)(n.p,{children:"TODO"})]})}function h(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(l,{...e})}):l(e)}},7511:(e,n,t)=>{t.d(n,{A:()=>i});const i=t.p+"assets/images/livekit-question-c57d67d9fe4eb6bbb6db3c8823fdc888.png"},8453:(e,n,t)=>{t.d(n,{R:()=>d,x:()=>a});var i=t(6540);const s={},o=i.createContext(s);function d(e){const n=i.useContext(o);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:d(e.components),i.createElement(o.Provider,{value:n},e.children)}}}]);